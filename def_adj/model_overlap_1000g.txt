model{

### DATA ###
# nsb = number of still births of alternative definition
# nsb28 = number of still births of 28wks definition
# n = number of observations
# n_1000 = number of observations of 1000gr definition, (first set among n observations)
# boxes refers to categories a, b, c
# ncombi[i] = number of possible values for b = box2

    # poisson zeroes trick for 1000g data
  for (i in 1:n_1000){
    for (index in 1:ncombis[i]){
      box2[i, index] <- min_intersect[i] + index - 1  
      contrL_invr[i, index] <- exp(contrLL_invr[i, index])
      box1[i, index] <- nsb[i] - box2[i, index]
      contrLL_invr[i,index] <- logdensity.multi(
          c(
            box1[i, index], 
            box2[i, index], 
            nsb28[i] - box2[i, index]
          ),
          p[i, 1:3], 
          box1[i, index] + nsb28[i]
                                      )
    }
    LL[i] <- log(sum(contrL_invr[i, 1:ncombis[i]])
                        + 0.000000000000000001)
    pois.mean[i] <- -LL[i] + 1
    zeroes[i] ~ dpois(pois.mean[i])
  }
  
  # likelihood for data on 1000grAND28 weeks
  for (i in (n_1000 + 1):n){
     nsb[i] ~ dbinom(p[i, 2]/(p[i, 2] + p[i, 3]), nsb28[i])
  }

### process model ###
  for (i in 1:n){
    kappa[i] <- exp(logkappa[i])
    logkappa[i] ~ dnorm(mu, tau)
    p_2plus3[i] ~ dunif(1/(1+kappa[i]), 1/(max(1,kappa[i])))
    p[i, 1] <- 1 - p_2plus3[i]
    p[i, 2] <- (kappa[i]+1)*p_2plus3[i] - 1
    p[i, 3] <- p_2plus3[i] - p[i, 2]
  }
  tau <- 1/sigma^2
  sigma ~ dnorm(0,1)T(0, )
  mu ~ dnorm(0, 0.05)

}